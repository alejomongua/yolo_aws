{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bd4e60b",
   "metadata": {},
   "source": [
    "# Training a YOLO implementation in pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b63c998",
   "metadata": {},
   "source": [
    "## Step 1: Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72702f59",
   "metadata": {},
   "source": [
    "### Upgrades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa8f5992",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8ce6e3",
   "metadata": {},
   "source": [
    "### Import requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be855f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.debugger import DebuggerHookConfig, CollectionConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68240cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOC_TAR = \"VOCtrainval_11-May-2012.tar\"\n",
    "# To do: Search for the bucket name by prefix\n",
    "BUCKET_NAME = 'sagemaker-20250212110251'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949c8579",
   "metadata": {},
   "source": [
    "### Initialize session and role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31cf2625",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bbbf47",
   "metadata": {},
   "source": [
    "### S3 locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd80c0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_s3_uri = f's3://{BUCKET_NAME}/datasets/{VOC_TAR}'\n",
    "# Folder where processed data is stored\n",
    "processed_prefix = 'datasets/processed/VOC'\n",
    "processed_data_s3_uri = f's3://{BUCKET_NAME}/{processed_prefix}'\n",
    "s3_debugger_output_path = f's3://{BUCKET_NAME}/debugger-output'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da85d67b",
   "metadata": {},
   "source": [
    "## Step 2: Preprocessing Job\n",
    "\n",
    "Create a ScriptProcessor to run a data preprocessing script.\n",
    "In this example, \"preprocess.py\" should be a script you create that:\n",
    "- Downloads and extracts the tar file.\n",
    "- Splits the dataset into training/validation/test sets.\n",
    "- Converts the dataset into a format (for example, preprocessed images and annotation files) that your training script expects.\n",
    "Upload this script into a local folder (e.g., \"preprocessing\") which you'll point to as your source_dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f0f0db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework='pytorch',\n",
    "    region=sagemaker_session.boto_region_name,\n",
    "    version='2.1.0',\n",
    "    py_version='py310',\n",
    "    image_scope='training',\n",
    "    instance_type='ml.m5.xlarge'\n",
    ")\n",
    "\n",
    "script_processor = ScriptProcessor(\n",
    "    command=['python3'],\n",
    "    image_uri=image_uri,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a057955c",
   "metadata": {},
   "source": [
    "### Run the processing job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6740ab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "\n",
    "# List objects under the processed data prefix\n",
    "response = s3.list_objects_v2(Bucket=BUCKET_NAME, Prefix=processed_prefix)\n",
    "if 'Contents' in response and len(response['Contents']) > 0:\n",
    "    print(\"Processed data already exists. Skipping processing job.\")\n",
    "else:\n",
    "    print(\"Processed data not found. Running processing job.\")\n",
    "    script_processor.run(\n",
    "        code='preprocessing/preprocess.py',\n",
    "        inputs=[\n",
    "            ProcessingInput(\n",
    "                source=raw_data_s3_uri,\n",
    "                destination='/opt/ml/processing/input'\n",
    "            )\n",
    "        ],\n",
    "        outputs=[\n",
    "            ProcessingOutput(\n",
    "                output_name='processed_data',\n",
    "                source='/opt/ml/processing/output',\n",
    "                destination=processed_data_s3_uri\n",
    "            )\n",
    "        ],\n",
    "        arguments=[\n",
    "            '--image_size', '448'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(\"Data preprocessing complete. Processed data available at:\",\n",
    "          processed_data_s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf9e30a",
   "metadata": {},
   "source": [
    "## Step 2: Launch a Training Job with Debugger\n",
    "\n",
    "### Define a Debugger hook configuration. This tells SageMaker which collections to capture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0950dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "debugger_hook_config = DebuggerHookConfig(\n",
    "    s3_output_path=s3_debugger_output_path,\n",
    "    # Saves debugger tensors every 100 steps\n",
    "    hook_parameters={\"save_interval\": \"100\"},\n",
    "    collection_configs=[\n",
    "        CollectionConfig(\"losses\"),      # Collects training/validation losses\n",
    "        CollectionConfig(\"gradients\"),   # Collects gradient information\n",
    "        CollectionConfig(\"weights\")      # Collects weight values\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94a8fe0",
   "metadata": {},
   "source": [
    "### Create a PyTorch estimator. Ensure your training code (e.g., train.py and supporting modules) is available in a source directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fcedee",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = PyTorch(\n",
    "    entry_point='training/train.py',\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    # instance_type='ml.p3.2xlarge',\n",
    "    instance_type='ml.g4dn.xlarge',\n",
    "    image_uri=image_uri,\n",
    "    framework_version='2.1.0',\n",
    "    py_version='py310',\n",
    "    debugger_hook_config=debugger_hook_config,\n",
    "    hyperparameters={\n",
    "        'epochs': 10,\n",
    "        'batch-size': 32,\n",
    "        'learning-rate': 0.001,\n",
    "        'data-dir': '/opt/ml/input/data/processed',\n",
    "        'load-weights': '',\n",
    "    },\n",
    "    debugger_rule_configs=[],\n",
    "    dependencies=['requirements.txt'],\n",
    "    command=[\"accelerate\", \"launch\", \"train.py\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac538dc5",
   "metadata": {},
   "source": [
    "### Define channel for preprocessed data.\n",
    "\n",
    "The processed data is output from the processing job and will be used as input for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1f25eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_channels = {\n",
    "    'processed': processed_data_s3_uri\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bb7449",
   "metadata": {},
   "source": [
    "### Launch the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1003678",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(inputs=data_channels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
